{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WGAN2_part3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Wasserstein GAN implementation, training was interrupted.\n",
        "\n",
        "Lsun data needs to be reshaped, different network structure & hyperparameters must be checked. FID calculation should be implemented.\n",
        "\n",
        "There is very much to be done until the project delivery."
      ],
      "metadata": {
        "id": "3HnZqu6ynGCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSO5g6CDJ8nv",
        "outputId": "273dd9ac-6af7-4daa-cea4-99e8ac3710cd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "zr0_aPDoqkRw",
        "outputId": "e023dc78-f2ba-4766-b648-dd4f0fccf882"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-023f3ed1-9de5-4af5-af0c-7810d6d8ec28\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-023f3ed1-9de5-4af5-af0c-7810d6d8ec28\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_QjeGwhknFlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download jhoward/lsun_bedroom"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59PA1uCqqoYr",
        "outputId": "5783c703-8bf6-43d6-be35-b74f0dcdc680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading lsun_bedroom.zip to /content\n",
            "100% 8.88G/8.89G [01:12<00:00, 104MB/s]\n",
            "100% 8.89G/8.89G [01:12<00:00, 132MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXFPJCVKHtBE",
        "outputId": "2f5037a7-b708-4c7b-a703-51c048ec18f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  kaggle.json  lsun_bedroom.zip  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "pathToDrive = \"drive/MyDrive/gan/\"\n",
        "\n",
        "for i in range(1,13):\n",
        "  zip_file = pathToDrive+\"savedGEN_wgan2_\" + str(i) + \".zip\"\n",
        "\n",
        "  try:\n",
        "    with zipfile.ZipFile(zip_file) as z:\n",
        "        z.extractall()\n",
        "        print(\"Extracted all\")\n",
        "  except:\n",
        "    print(\"Invalid file\")\n",
        "\n",
        "\n",
        "  zip_file = pathToDrive+\"savedDIS_wgan2_\" + str(i) + \".zip\"\n",
        "\n",
        "  try:\n",
        "    with zipfile.ZipFile(zip_file) as z:\n",
        "        z.extractall()\n",
        "        print(\"Extracted all\")\n",
        "  except:\n",
        "    print(\"Invalid file\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VAtPJAkHcfQ",
        "outputId": "9c591b31-ca43-4dab-e02b-bb4058db4268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted all\n",
            "Extracted all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        " \n",
        "zip_file = \"/content/lsun_bedroom.zip\"\n",
        " \n",
        "try:\n",
        "    with zipfile.ZipFile(zip_file) as z:\n",
        "        z.extractall()\n",
        "        print(\"Extracted all\")\n",
        "except:\n",
        "    print(\"Invalid file\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJuse_BqqobU",
        "outputId": "f64c938a-15ff-4735-8719-a6504aaa7c75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "V-IfdNFNqoeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing dataset"
      ],
      "metadata": {
        "id": "2AJK0HxtI9YZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JnjsgS-Ro9ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "def load_images_from_folder_recursively(folder,from_ind, to_ind):\n",
        "  images = []\n",
        "  counter = 0\n",
        "  for filename in glob.iglob(folder + '**/*.jpg', recursive=True):\n",
        "    counter = counter + 1\n",
        "    if(counter < from_ind):\n",
        "          continue\n",
        "    if(counter % to_ind == 0):\n",
        "      break\n",
        "    img = cv2.imread(filename)\n",
        "    if img is not None:\n",
        "      images.append(np.float32(cv2.resize(img, (64,64))))\n",
        "    #print(filename)\n",
        "    #break\n",
        "  return images"
      ],
      "metadata": {
        "id": "BMBLVYTBW9B2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SHAPE = (64, 64, 3)\n",
        "BATCH_SIZE = 128\n",
        "# Size of the noise vector\n",
        "noise_dim = 1024"
      ],
      "metadata": {
        "id": "2HDYX8_ZqovA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discriminator"
      ],
      "metadata": {
        "id": "1VnZ8qUcZ_tF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DISCRiMINATOR\n",
        "\n",
        "def conv_block(\n",
        "    x,\n",
        "    filters,\n",
        "    activation,\n",
        "    kernel_size=(3, 3),\n",
        "    strides=(1, 1),\n",
        "    padding=\"same\",\n",
        "    use_bias=True,\n",
        "    use_bn=False,\n",
        "    use_dropout=False,\n",
        "    drop_value=0.5,\n",
        "):\n",
        "    x = layers.Conv2D(\n",
        "        filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias\n",
        "    )(x)\n",
        "    if use_bn:\n",
        "        x = layers.BatchNormalization()(x)\n",
        "    x = activation(x)\n",
        "    if use_dropout:\n",
        "        x = layers.Dropout(drop_value)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_discriminator_model():\n",
        "    img_input = layers.Input(shape=IMG_SHAPE)\n",
        "    # Zero pad the input to make the input images size to (32, 32, 1).\n",
        "    x = layers.ZeroPadding2D((2, 2))(img_input)\n",
        "    x = conv_block(\n",
        "        x,\n",
        "        128,\n",
        "        kernel_size=(5, 5),\n",
        "        strides=(2, 2),\n",
        "        use_bn=False,\n",
        "        use_bias=True,\n",
        "        activation=layers.LeakyReLU(0.2),\n",
        "        use_dropout=False,\n",
        "        drop_value=0.3,\n",
        "    )\n",
        "\n",
        "    x = conv_block(\n",
        "        x,\n",
        "        64,\n",
        "        kernel_size=(5, 5),\n",
        "        strides=(2, 2),\n",
        "        use_bn=False,\n",
        "        activation=layers.LeakyReLU(0.2),\n",
        "        use_bias=True,\n",
        "        use_dropout=True,\n",
        "        drop_value=0.3,\n",
        "    )\n",
        "    # x = conv_block(\n",
        "    #     x,\n",
        "    #     512,\n",
        "    #     kernel_size=(5, 5),\n",
        "    #     strides=(2, 2),\n",
        "    #     use_bn=False,\n",
        "    #     activation=layers.LeakyReLU(0.2),\n",
        "    #     use_bias=True,\n",
        "    #     use_dropout=False,\n",
        "    #     drop_value=0.3,\n",
        "    # )\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.Dense(1)(x)\n",
        "\n",
        "    d_model = keras.models.Model(img_input, x, name=\"discriminator\")\n",
        "    return d_model\n",
        "\n",
        "\n",
        "d_model = get_discriminator_model()\n",
        "d_model.summary()\n"
      ],
      "metadata": {
        "id": "soIjNbytqow2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2171456-e47c-46c9-d5b8-b08ed154f1b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " zero_padding2d (ZeroPadding  (None, 68, 68, 3)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 34, 34, 128)       9728      \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 34, 34, 128)       0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 17, 17, 64)        204864    \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 17, 17, 64)        0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 17, 17, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 18496)             0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 18496)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 18497     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 233,089\n",
            "Trainable params: 233,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generator"
      ],
      "metadata": {
        "id": "2kiZJdqnaFU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upsample_block(\n",
        "    x,\n",
        "    filters,\n",
        "    activation,\n",
        "    kernel_size=(3, 3),\n",
        "    strides=(1, 1),\n",
        "    up_size=(2, 2),\n",
        "    padding=\"same\",\n",
        "    use_bn=False,\n",
        "    use_bias=True,\n",
        "    use_dropout=False,\n",
        "    drop_value=0.2,\n",
        "):\n",
        "    x = layers.UpSampling2D(up_size)(x)\n",
        "    x = layers.Conv2D(\n",
        "        filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias\n",
        "    )(x)\n",
        "\n",
        "    if use_bn:\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "    if activation:\n",
        "        x = activation(x)\n",
        "    if use_dropout:\n",
        "        x = layers.Dropout(drop_value)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_generator_model():\n",
        "    noise = layers.Input(shape=(noise_dim,))\n",
        "    x = layers.Dense(8 * 8 * 2 , use_bias=False)(noise)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = layers.Reshape((8, 8, 2))(x)\n",
        "    x = upsample_block(\n",
        "        x,\n",
        "        256,\n",
        "        layers.LeakyReLU(0.2),\n",
        "        strides=(1, 1),\n",
        "        use_bias=False,\n",
        "        use_bn=True,\n",
        "        padding=\"same\",\n",
        "        use_dropout=True,\n",
        "    )\n",
        "    x = upsample_block(\n",
        "        x,\n",
        "        64,\n",
        "        layers.LeakyReLU(0.2),\n",
        "        strides=(1, 1),\n",
        "        use_bias=False,\n",
        "        use_bn=True,\n",
        "        padding=\"same\",\n",
        "        use_dropout=True,\n",
        "    )\n",
        "    x = upsample_block(\n",
        "        x, 3, layers.Activation(\"tanh\"), strides=(1, 1), use_bias=False, use_bn=True\n",
        "    )\n",
        "    # At this point, we have an output which has the same shape as the input, (32, 32, 1).\n",
        "    # We will use a Cropping2D layer to make it (28, 28, 1).\n",
        "    # x = layers.Cropping2D((2, 2))(x)\n",
        "\n",
        "    g_model = keras.models.Model(noise, x, name=\"generator\")\n",
        "    return g_model\n",
        "\n",
        "\n",
        "g_model = get_generator_model()\n",
        "g_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNUnQqyVaJGa",
        "outputId": "f9844e3d-4057-4d62-eaf5-c9313cf4e211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1024)]            0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               131072    \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 128)              512       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 128)               0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 8, 8, 2)           0         \n",
            "                                                                 \n",
            " up_sampling2d (UpSampling2D  (None, 16, 16, 2)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 256)       4608      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 16, 16, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " up_sampling2d_1 (UpSampling  (None, 32, 32, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 64)        147456    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 32, 32, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " up_sampling2d_2 (UpSampling  (None, 64, 64, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 64, 64, 3)         1728      \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 64, 64, 3)        12        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 64, 64, 3)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 286,668\n",
            "Trainable params: 285,766\n",
            "Non-trainable params: 902\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WGAN Monitor"
      ],
      "metadata": {
        "id": "IWYc0Q2DzOKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_img_dir = \"/content/gan1_images\"\n",
        "\n",
        "!mkdir /content/gan1_images"
      ],
      "metadata": {
        "id": "peT_KFAD--TT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eab18836-a32a-4a83-e420-825f69dc19fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/gan1_images’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GANMonitor(keras.callbacks.Callback):\n",
        "    def __init__(self, num_img=6, latent_dim=1024):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images = (generated_images * 127.5) + 127.5\n",
        "\n",
        "        for i in range(self.num_img):\n",
        "            img = generated_images[i].numpy()\n",
        "            img = keras.preprocessing.image.array_to_img(img)\n",
        "            img.save(gen_img_dir + \"/generated_img_{i}_{epoch}.png\".format(i=i, epoch=epoch))\n"
      ],
      "metadata": {
        "id": "xvM4j-s5zN3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WGAN-GP model"
      ],
      "metadata": {
        "id": "FSNlu_XeaaYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WGAN(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        discriminator,\n",
        "        generator,\n",
        "        latent_dim,\n",
        "        discriminator_extra_steps=2,\n",
        "        gp_weight=10.0,\n",
        "    ):\n",
        "        super(WGAN, self).__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.d_steps = discriminator_extra_steps\n",
        "        self.gp_weight = gp_weight\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n",
        "        super(WGAN, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.d_loss_fn = d_loss_fn\n",
        "        self.g_loss_fn = g_loss_fn\n",
        "\n",
        "    def gradient_penalty(self, batch_size, real_images, fake_images):\n",
        "        \"\"\" Calculates the gradient penalty.\n",
        "\n",
        "        This loss is calculated on an interpolated image\n",
        "        and added to the discriminator loss.\n",
        "        \"\"\"\n",
        "        # Get the interpolated image\n",
        "        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
        "        diff = fake_images - real_images\n",
        "        interpolated = real_images + alpha * diff\n",
        "\n",
        "        with tf.GradientTape() as gp_tape:\n",
        "            gp_tape.watch(interpolated)\n",
        "            # 1. Get the discriminator output for this interpolated image.\n",
        "            pred = self.discriminator(interpolated, training=True)\n",
        "\n",
        "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
        "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
        "        # 3. Calculate the norm of the gradients.\n",
        "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
        "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
        "        return gp\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        if isinstance(real_images, tuple):\n",
        "            real_images = real_images[0]\n",
        "\n",
        "        # Get the batch size\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "\n",
        "        # For each batch, we are going to perform the\n",
        "        # following steps as laid out in the original paper:\n",
        "        # 1. Train the generator and get the generator loss\n",
        "        # 2. Train the discriminator and get the discriminator loss\n",
        "        # 3. Calculate the gradient penalty\n",
        "        # 4. Multiply this gradient penalty with a constant weight factor\n",
        "        # 5. Add the gradient penalty to the discriminator loss\n",
        "        # 6. Return the generator and discriminator losses as a loss dictionary\n",
        "\n",
        "        # Train the discriminator first. The original paper recommends training\n",
        "        # the discriminator for `x` more steps (typically 5) as compared to\n",
        "        # one step of the generator. Here we will train it for 2 extra steps\n",
        "        # as compared to 5 to reduce the training time.\n",
        "        for i in range(self.d_steps):\n",
        "            # Get the latent vector\n",
        "            random_latent_vectors = tf.random.normal(\n",
        "                shape=(batch_size, self.latent_dim)\n",
        "            )\n",
        "            with tf.GradientTape() as tape:\n",
        "                # Generate fake images from the latent vector\n",
        "                fake_images = self.generator(random_latent_vectors, training=True)\n",
        "\n",
        "                # NOISED FAKE IMAGES ( vs mode collapse)\n",
        "                fake_images2 = fake_images + np.random.normal(0,0.001, size = (fake_images.shape[1],fake_images.shape[2],fake_images.shape[3]))\n",
        "                \n",
        "\n",
        "                # Get the logits for the fake images\n",
        "                fake_logits = self.discriminator(fake_images2, training=True)\n",
        "\n",
        "                # NOISED REAL IMAGES ( vs mode collapse)\n",
        "                real_images2 = real_images + np.random.normal(0,0.001, size = (real_images.shape[1],real_images.shape[2],real_images.shape[3]))\n",
        "                \n",
        "\n",
        "\n",
        "                # Get the logits for the real images\n",
        "                real_logits = self.discriminator(real_images2, training=True)\n",
        "\n",
        "                # Calculate the discriminator loss using the fake and real image logits\n",
        "                d_cost = self.d_loss_fn(real_img=real_logits, fake_img=fake_logits)\n",
        "\n",
        "\n",
        "                # Calculate the gradient penalty\n",
        "\n",
        "                gp = self.gradient_penalty(batch_size, real_images2, fake_images2)\n",
        "                # Add the gradient penalty to the original discriminator loss\n",
        "                d_loss = d_cost + gp * self.gp_weight\n",
        "\n",
        "            # Get the gradients w.r.t the discriminator loss\n",
        "            d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
        "            # Update the weights of the discriminator using the discriminator optimizer\n",
        "            self.d_optimizer.apply_gradients(\n",
        "                zip(d_gradient, self.discriminator.trainable_variables)\n",
        "            )\n",
        "\n",
        "        # Train the generator\n",
        "        # Get the latent vector\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Generate fake images using the generator\n",
        "            generated_images = self.generator(random_latent_vectors, training=True)\n",
        "            # Get the discriminator logits for fake images\n",
        "            gen_img_logits = self.discriminator(generated_images, training=True)\n",
        "            # Calculate the generator loss\n",
        "            g_loss = self.g_loss_fn(gen_img_logits)\n",
        "\n",
        "        # Get the gradients w.r.t the generator loss\n",
        "        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
        "        # Update the weights of the generator using the generator optimizer\n",
        "        self.g_optimizer.apply_gradients(\n",
        "            zip(gen_gradient, self.generator.trainable_variables)\n",
        "        )\n",
        "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}\n"
      ],
      "metadata": {
        "id": "RkBaUAOjaJXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the GAN model"
      ],
      "metadata": {
        "id": "9hBUvqGQamJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the optimizer for both networks\n",
        "# (learning_rate=0.0002, beta_1=0.5 are recommended)\n",
        "\n",
        "# update: CHANGING learning rate to 0.002\n",
        "generator_optimizer = keras.optimizers.Adam(\n",
        "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",
        ")\n",
        "discriminator_optimizer = keras.optimizers.Adam(\n",
        "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",
        ")\n",
        "\n",
        "# Define the loss functions for the discriminator,\n",
        "# which should be (fake_loss - real_loss).\n",
        "# We will add the gradient penalty later to this loss function.\n",
        "def discriminator_loss(real_img, fake_img):\n",
        "    real_loss = tf.reduce_mean(real_img)\n",
        "    fake_loss = tf.reduce_mean(fake_img)\n",
        "    return fake_loss - real_loss\n",
        "\n",
        "\n",
        "# Define the loss functions for the generator.\n",
        "def generator_loss(fake_img):\n",
        "    return -tf.reduce_mean(fake_img)\n",
        "\n",
        "\n",
        "# Set the number of epochs for trainining.\n",
        "epochs = 3\n",
        "\n",
        "# Instantiate the customer `GANMonitor` Keras callback.\n",
        "cbk = GANMonitor(num_img=3, latent_dim=noise_dim)\n",
        "\n",
        "# Instantiate the WGAN model.\n",
        "wgan = WGAN(\n",
        "    discriminator=d_model,\n",
        "    generator=g_model,\n",
        "    latent_dim=noise_dim,\n",
        "    discriminator_extra_steps=2,\n",
        ")\n",
        "\n",
        "wgan.discriminator.compile(optimizer = discriminator_optimizer)\n",
        "wgan.generator.compile(optimizer = generator_optimizer)\n",
        "\n",
        "# Compile the WGAN model.\n",
        "wgan.compile(\n",
        "    d_optimizer=discriminator_optimizer,\n",
        "    g_optimizer=generator_optimizer,\n",
        "    g_loss_fn=generator_loss,\n",
        "    d_loss_fn=discriminator_loss,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "EOdjAPJfalsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "lF6dkYHnzR_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading saved models\n",
        "\n",
        "gg = keras.models.load_model('savedGEN_wgan2_13')\n",
        "dd = keras.models.load_model('savedDIS_wgan2_13')\n",
        "wgan.discriminator = dd\n",
        "wgan.generator = gg\n"
      ],
      "metadata": {
        "id": "IiRhmS6ybxle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First 3 epochs - by chunks of 1/6 of data"
      ],
      "metadata": {
        "id": "PdLwvDK1WfD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_img_folder = \"/content/data0/lsun/bedroom/\""
      ],
      "metadata": {
        "id": "mpymRAcrgptM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLi6YD83sz6M",
        "outputId": "a18344fa-2665-4015-ca30-e5187a61df4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indeksior = 0\n",
        "\n",
        "aux = load_images_from_folder_recursively(path_to_img_folder, from_ind = indeksior, to_ind = indeksior + 50000)\n",
        "aux = np.array(aux)\n",
        "aux = (aux - 127.5) / 127.5\n",
        "\n",
        "# Continue training the model.\n",
        "wgan.fit(aux, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])\n",
        "\n",
        "gen_to_save = wgan.generator\n",
        "dis_to_save = wgan.discriminator\n",
        "gen_to_save.save(\"savedGEN_wgan2_1\")\n",
        "dis_to_save.save(\"savedDIS_wgan2_1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6ugnDPMVu8i",
        "outputId": "0a7ded47-9820-4f7c-b63e-dbe427d20548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "391/391 [==============================] - 153s 353ms/step - d_loss: -12.0744 - g_loss: 3.2506\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 142s 362ms/step - d_loss: -11.4108 - g_loss: -29.2819\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 143s 365ms/step - d_loss: -9.7867 - g_loss: -25.8926\n",
            "INFO:tensorflow:Assets written to: savedGEN_wgan2_1/assets\n",
            "INFO:tensorflow:Assets written to: savedDIS_wgan2_1/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indeksior = 50000\n",
        "\n",
        "aux = load_images_from_folder_recursively(path_to_img_folder, from_ind = indeksior, to_ind = indeksior + 50000)\n",
        "aux = np.array(aux)\n",
        "aux = (aux - 127.5) / 127.5\n",
        "\n",
        "# Continue training the model.\n",
        "wgan.fit(aux, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])\n",
        "\n",
        "gen_to_save = wgan.generator\n",
        "dis_to_save = wgan.discriminator\n",
        "gen_to_save.save(\"savedGEN_wgan2_2\")\n",
        "dis_to_save.save(\"savedDIS_wgan2_2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViDvPAb0g5ou",
        "outputId": "dc63f8e0-8a73-47be-bea3-03c74ed1b63a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "391/391 [==============================] - 139s 356ms/step - d_loss: -9.3633 - g_loss: -23.3332\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 142s 363ms/step - d_loss: -9.5352 - g_loss: -26.0110\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 143s 365ms/step - d_loss: -9.2675 - g_loss: -37.3709\n",
            "INFO:tensorflow:Assets written to: savedGEN_wgan2_2/assets\n",
            "INFO:tensorflow:Assets written to: savedDIS_wgan2_2/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indeksior = 100000\n",
        "\n",
        "aux = load_images_from_folder_recursively(path_to_img_folder, from_ind = indeksior, to_ind = indeksior + 50000)\n",
        "aux = np.array(aux)\n",
        "aux = (aux - 127.5) / 127.5\n",
        "\n",
        "# Continue training the model.\n",
        "wgan.fit(aux, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])\n",
        "\n",
        "gen_to_save = wgan.generator\n",
        "dis_to_save = wgan.discriminator\n",
        "gen_to_save.save(\"savedGEN_wgan2_3\")\n",
        "dis_to_save.save(\"savedDIS_wgan2_3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR2a4547g5ss",
        "outputId": "cd51cabf-3de7-45f3-8860-f7d0740583d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "391/391 [==============================] - 138s 352ms/step - d_loss: -8.8992 - g_loss: -49.6634\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 142s 362ms/step - d_loss: -8.6152 - g_loss: -64.2643\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 143s 365ms/step - d_loss: -8.2311 - g_loss: -77.5218\n",
            "INFO:tensorflow:Assets written to: savedGEN_wgan2_3/assets\n",
            "INFO:tensorflow:Assets written to: savedDIS_wgan2_3/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indeksior = 150000\n",
        "\n",
        "aux = load_images_from_folder_recursively(path_to_img_folder, from_ind = indeksior, to_ind = indeksior + 50000)\n",
        "aux = np.array(aux)\n",
        "aux = (aux - 127.5) / 127.5\n",
        "\n",
        "# Continue training the model.\n",
        "wgan.fit(aux, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])\n",
        "\n",
        "gen_to_save = wgan.generator\n",
        "dis_to_save = wgan.discriminator\n",
        "gen_to_save.save(\"savedGEN_wgan2_4\")\n",
        "dis_to_save.save(\"savedDIS_wgan2_4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQy3YLGGg5xg",
        "outputId": "a808668d-cdd6-45a8-e02c-c997d846db9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "391/391 [==============================] - 142s 364ms/step - d_loss: -7.9645 - g_loss: -77.3032\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 145s 370ms/step - d_loss: -7.5432 - g_loss: -87.5755\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 145s 371ms/step - d_loss: -7.3618 - g_loss: -84.9688\n",
            "INFO:tensorflow:Assets written to: savedGEN_wgan2_4/assets\n",
            "INFO:tensorflow:Assets written to: savedDIS_wgan2_4/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indeksior = 200000\n",
        "\n",
        "aux = load_images_from_folder_recursively(path_to_img_folder, from_ind = indeksior, to_ind = indeksior + 50000)\n",
        "aux = np.array(aux)\n",
        "aux = (aux - 127.5) / 127.5\n",
        "\n",
        "# Continue training the model.\n",
        "wgan.fit(aux, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])\n",
        "\n",
        "gen_to_save = wgan.generator\n",
        "dis_to_save = wgan.discriminator\n",
        "gen_to_save.save(\"savedGEN_wgan2_5\")\n",
        "dis_to_save.save(\"savedDIS_wgan2_5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyyTLWZOg52Y",
        "outputId": "36e6e033-be15-4abe-825a-f0d81a8e889d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "391/391 [==============================] - 144s 369ms/step - d_loss: -7.1606 - g_loss: -80.4770\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 145s 370ms/step - d_loss: -6.9758 - g_loss: -79.7046\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 145s 371ms/step - d_loss: -7.0064 - g_loss: -84.7911\n",
            "INFO:tensorflow:Assets written to: savedGEN_wgan2_5/assets\n",
            "INFO:tensorflow:Assets written to: savedDIS_wgan2_5/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indeksior = 250000\n",
        "\n",
        "aux = load_images_from_folder_recursively(path_to_img_folder, from_ind = indeksior, to_ind = indeksior + 50000)\n",
        "aux = np.array(aux)\n",
        "aux = (aux - 127.5) / 127.5\n",
        "\n",
        "# Continue training the model.\n",
        "wgan.fit(aux, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])\n",
        "\n",
        "gen_to_save = wgan.generator\n",
        "dis_to_save = wgan.discriminator\n",
        "gen_to_save.save(\"savedGEN_wgan2_6\")\n",
        "dis_to_save.save(\"savedDIS_wgan2_6\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StCjVE2Pg56B",
        "outputId": "ded85100-877e-4ea1-eddb-f6f04ef5e7c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "391/391 [==============================] - 145s 370ms/step - d_loss: -6.9121 - g_loss: -83.8120\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 145s 370ms/step - d_loss: -6.7115 - g_loss: -88.7089\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 146s 373ms/step - d_loss: -6.5669 - g_loss: -90.1241\n",
            "INFO:tensorflow:Assets written to: savedGEN_wgan2_6/assets\n",
            "INFO:tensorflow:Assets written to: savedDIS_wgan2_6/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r savedDIS_wgan2_1.zip savedDIS_wgan2_1/\n",
        "!zip -r savedGEN_wgan2_1.zip savedGEN_wgan2_1/\n",
        "!zip -r savedDIS_wgan2_2.zip savedDIS_wgan2_2/\n",
        "!zip -r savedGEN_wgan2_2.zip savedGEN_wgan2_2/\n",
        "!zip -r savedDIS_wgan2_3.zip savedDIS_wgan2_3/\n",
        "!zip -r savedGEN_wgan2_3.zip savedGEN_wgan2_3/\n",
        "!zip -r savedDIS_wgan2_4.zip savedDIS_wgan2_4/\n",
        "!zip -r savedGEN_wgan2_4.zip savedGEN_wgan2_4/\n",
        "!zip -r savedDIS_wgan2_5.zip savedDIS_wgan2_5/\n",
        "!zip -r savedGEN_wgan2_5.zip savedGEN_wgan2_5/\n",
        "!zip -r savedDIS_wgan2_6.zip savedDIS_wgan2_6/\n",
        "!zip -r savedGEN_wgan2_6.zip savedGEN_wgan2_6/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlLkpzNchJI6",
        "outputId": "351d8f33-6dc0-4259-d5d4-8fa34a5dcac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: savedDIS_wgan2_1/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_1/saved_model.pb (deflated 89%)\n",
            "  adding: savedDIS_wgan2_1/assets/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_1/variables/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_1/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: savedDIS_wgan2_1/variables/variables.index (deflated 63%)\n",
            "  adding: savedDIS_wgan2_1/keras_metadata.pb (deflated 90%)\n",
            "  adding: savedGEN_wgan2_1/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_1/saved_model.pb (deflated 90%)\n",
            "  adding: savedGEN_wgan2_1/assets/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_1/variables/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_1/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: savedGEN_wgan2_1/variables/variables.index (deflated 68%)\n",
            "  adding: savedGEN_wgan2_1/keras_metadata.pb (deflated 92%)\n",
            "  adding: savedDIS_wgan2_2/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_2/saved_model.pb (deflated 88%)\n",
            "  adding: savedDIS_wgan2_2/assets/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_2/variables/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_2/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: savedDIS_wgan2_2/variables/variables.index (deflated 62%)\n",
            "  adding: savedDIS_wgan2_2/keras_metadata.pb (deflated 90%)\n",
            "  adding: savedGEN_wgan2_2/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_2/saved_model.pb (deflated 89%)\n",
            "  adding: savedGEN_wgan2_2/assets/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_2/variables/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_2/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "  adding: savedGEN_wgan2_2/variables/variables.index (deflated 68%)\n",
            "  adding: savedGEN_wgan2_2/keras_metadata.pb (deflated 92%)\n",
            "  adding: savedDIS_wgan2_3/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_3/saved_model.pb (deflated 88%)\n",
            "  adding: savedDIS_wgan2_3/assets/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_3/variables/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_3/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: savedDIS_wgan2_3/variables/variables.index (deflated 62%)\n",
            "  adding: savedDIS_wgan2_3/keras_metadata.pb (deflated 90%)\n",
            "  adding: savedGEN_wgan2_3/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_3/saved_model.pb (deflated 89%)\n",
            "  adding: savedGEN_wgan2_3/assets/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_3/variables/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_3/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "  adding: savedGEN_wgan2_3/variables/variables.index (deflated 68%)\n",
            "  adding: savedGEN_wgan2_3/keras_metadata.pb (deflated 92%)\n",
            "  adding: savedDIS_wgan2_4/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_4/saved_model.pb (deflated 88%)\n",
            "  adding: savedDIS_wgan2_4/assets/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_4/variables/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_4/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: savedDIS_wgan2_4/variables/variables.index (deflated 62%)\n",
            "  adding: savedDIS_wgan2_4/keras_metadata.pb (deflated 90%)\n",
            "  adding: savedGEN_wgan2_4/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_4/saved_model.pb (deflated 89%)\n",
            "  adding: savedGEN_wgan2_4/assets/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_4/variables/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_4/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "  adding: savedGEN_wgan2_4/variables/variables.index (deflated 68%)\n",
            "  adding: savedGEN_wgan2_4/keras_metadata.pb (deflated 92%)\n",
            "  adding: savedDIS_wgan2_5/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_5/saved_model.pb (deflated 88%)\n",
            "  adding: savedDIS_wgan2_5/assets/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_5/variables/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_5/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: savedDIS_wgan2_5/variables/variables.index (deflated 62%)\n",
            "  adding: savedDIS_wgan2_5/keras_metadata.pb (deflated 90%)\n",
            "  adding: savedGEN_wgan2_5/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_5/saved_model.pb (deflated 89%)\n",
            "  adding: savedGEN_wgan2_5/assets/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_5/variables/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_5/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "  adding: savedGEN_wgan2_5/variables/variables.index (deflated 68%)\n",
            "  adding: savedGEN_wgan2_5/keras_metadata.pb (deflated 92%)\n",
            "  adding: savedDIS_wgan2_6/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_6/saved_model.pb (deflated 88%)\n",
            "  adding: savedDIS_wgan2_6/assets/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_6/variables/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_6/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: savedDIS_wgan2_6/variables/variables.index (deflated 62%)\n",
            "  adding: savedDIS_wgan2_6/keras_metadata.pb (deflated 90%)\n",
            "  adding: savedGEN_wgan2_6/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_6/saved_model.pb (deflated 89%)\n",
            "  adding: savedGEN_wgan2_6/assets/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_6/variables/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_6/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "  adding: savedGEN_wgan2_6/variables/variables.index (deflated 68%)\n",
            "  adding: savedGEN_wgan2_6/keras_metadata.pb (deflated 92%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Epochs 4-7 - by chunks of 1/6 of data"
      ],
      "metadata": {
        "id": "OYtIDnfW_mam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_img_folder = \"/content/data0/lsun/bedroom/\""
      ],
      "metadata": {
        "id": "U0IMKRDJ_mao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 4"
      ],
      "metadata": {
        "id": "nuO400J4_maq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indeksior = 0\n",
        "\n",
        "aux = load_images_from_folder_recursively(path_to_img_folder, from_ind = indeksior, to_ind = indeksior + 50000)\n",
        "aux = np.array(aux)\n",
        "aux = (aux - 127.5) / 127.5\n",
        "\n",
        "# Continue training the model.\n",
        "wgan.fit(aux, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])\n",
        "\n",
        "gen_to_save = wgan.generator\n",
        "dis_to_save = wgan.discriminator\n",
        "gen_to_save.save(\"savedGEN_wgan2_7\")\n",
        "dis_to_save.save(\"savedDIS_wgan2_7\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e63693b-44b8-4c9f-a2a1-1ff7a27da194",
        "id": "wx0pVjbc_mas"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "391/391 [==============================] - 145s 370ms/step - d_loss: -6.6202 - g_loss: -91.8851\n",
            "Epoch 2/4\n",
            "391/391 [==============================] - 145s 371ms/step - d_loss: -6.4662 - g_loss: -92.4255\n",
            "Epoch 3/4\n",
            "391/391 [==============================] - 145s 370ms/step - d_loss: -6.4318 - g_loss: -99.2505\n",
            "Epoch 4/4\n",
            "391/391 [==============================] - 145s 371ms/step - d_loss: -6.4424 - g_loss: -97.2457\n",
            "INFO:tensorflow:Assets written to: savedGEN_wgan2_7/assets\n",
            "INFO:tensorflow:Assets written to: savedDIS_wgan2_7/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indeksior = 50000\n",
        "\n",
        "aux = load_images_from_folder_recursively(path_to_img_folder, from_ind = indeksior, to_ind = indeksior + 50000)\n",
        "aux = np.array(aux)\n",
        "aux = (aux - 127.5) / 127.5\n",
        "\n",
        "# Continue training the model.\n",
        "wgan.fit(aux, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])\n",
        "\n",
        "gen_to_save = wgan.generator\n",
        "dis_to_save = wgan.discriminator\n",
        "gen_to_save.save(\"savedGEN_wgan2_8\")\n",
        "dis_to_save.save(\"savedDIS_wgan2_8\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "798269cc-fb13-4487-c43d-27221d966f1a",
        "id": "tkFqkZ_s_mat"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "391/391 [==============================] - 145s 370ms/step - d_loss: -6.3353 - g_loss: -103.7144\n",
            "Epoch 2/4\n",
            "391/391 [==============================] - 145s 371ms/step - d_loss: -6.2986 - g_loss: -99.1024\n",
            "Epoch 3/4\n",
            "391/391 [==============================] - 145s 371ms/step - d_loss: -6.3061 - g_loss: -98.6574\n",
            "Epoch 4/4\n",
            "391/391 [==============================] - 145s 370ms/step - d_loss: -6.3485 - g_loss: -92.7957\n",
            "INFO:tensorflow:Assets written to: savedGEN_wgan2_8/assets\n",
            "INFO:tensorflow:Assets written to: savedDIS_wgan2_8/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indeksior = 100000\n",
        "\n",
        "aux = load_images_from_folder_recursively(path_to_img_folder, from_ind = indeksior, to_ind = indeksior + 50000)\n",
        "aux = np.array(aux)\n",
        "aux = (aux - 127.5) / 127.5\n",
        "\n",
        "# Continue training the model.\n",
        "wgan.fit(aux, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])\n",
        "\n",
        "gen_to_save = wgan.generator\n",
        "dis_to_save = wgan.discriminator\n",
        "gen_to_save.save(\"savedGEN_wgan2_9\")\n",
        "dis_to_save.save(\"savedDIS_wgan2_9\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea1ea419-ba57-4ee4-b8fd-02c86130127e",
        "id": "kZiVaFOs_mav"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "391/391 [==============================] - 145s 370ms/step - d_loss: -6.2572 - g_loss: -94.0127\n",
            "Epoch 2/4\n",
            "391/391 [==============================] - 145s 371ms/step - d_loss: -6.2006 - g_loss: -93.9105\n",
            "Epoch 3/4\n",
            "391/391 [==============================] - 145s 371ms/step - d_loss: -6.2885 - g_loss: -90.3551\n",
            "Epoch 4/4\n",
            "391/391 [==============================] - 145s 371ms/step - d_loss: -6.2465 - g_loss: -87.0135\n",
            "INFO:tensorflow:Assets written to: savedGEN_wgan2_9/assets\n",
            "INFO:tensorflow:Assets written to: savedDIS_wgan2_9/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indeksior = 150000\n",
        "\n",
        "aux = load_images_from_folder_recursively(path_to_img_folder, from_ind = indeksior, to_ind = indeksior + 50000)\n",
        "aux = np.array(aux)\n",
        "aux = (aux - 127.5) / 127.5\n",
        "\n",
        "# Continue training the model.\n",
        "wgan.fit(aux, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])\n",
        "\n",
        "gen_to_save = wgan.generator\n",
        "dis_to_save = wgan.discriminator\n",
        "gen_to_save.save(\"savedGEN_wgan2_10\")\n",
        "dis_to_save.save(\"savedDIS_wgan2_10\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5b1b552-7d51-4e2b-f19b-3bbb428aa476",
        "id": "A24YlNxn_may"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "391/391 [==============================] - 144s 369ms/step - d_loss: -6.2465 - g_loss: -84.7741\n",
            "Epoch 2/4\n",
            "391/391 [==============================] - 145s 370ms/step - d_loss: -6.2570 - g_loss: -81.1704\n",
            "Epoch 3/4\n",
            "391/391 [==============================] - 145s 370ms/step - d_loss: -6.2106 - g_loss: -83.6453\n",
            "Epoch 4/4\n",
            "391/391 [==============================] - 145s 371ms/step - d_loss: -6.1517 - g_loss: -84.2216\n",
            "INFO:tensorflow:Assets written to: savedGEN_wgan2_10/assets\n",
            "INFO:tensorflow:Assets written to: savedDIS_wgan2_10/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indeksior = 200000\n",
        "\n",
        "aux = load_images_from_folder_recursively(path_to_img_folder, from_ind = indeksior, to_ind = indeksior + 50000)\n",
        "aux = np.array(aux)\n",
        "aux = (aux - 127.5) / 127.5\n",
        "\n",
        "# Continue training the model.\n",
        "wgan.fit(aux, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])\n",
        "\n",
        "gen_to_save = wgan.generator\n",
        "dis_to_save = wgan.discriminator\n",
        "gen_to_save.save(\"savedGEN_wgan2_11\")\n",
        "dis_to_save.save(\"savedDIS_wgan2_11\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00009c39-0ff5-4cb9-b239-adff1987189b",
        "id": "TJvEbG5g_ma0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "391/391 [==============================] - 144s 369ms/step - d_loss: -6.1685 - g_loss: -84.2924\n",
            "Epoch 2/4\n",
            "391/391 [==============================] - 145s 371ms/step - d_loss: -6.1104 - g_loss: -81.8294\n",
            "Epoch 3/4\n",
            "391/391 [==============================] - 145s 370ms/step - d_loss: -6.1508 - g_loss: -81.0786\n",
            "Epoch 4/4\n",
            "391/391 [==============================] - 145s 370ms/step - d_loss: -6.0353 - g_loss: -72.7118\n",
            "INFO:tensorflow:Assets written to: savedGEN_wgan2_11/assets\n",
            "INFO:tensorflow:Assets written to: savedDIS_wgan2_11/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indeksior = 250000\n",
        "\n",
        "aux = load_images_from_folder_recursively(path_to_img_folder, from_ind = indeksior, to_ind = indeksior + 50000)\n",
        "aux = np.array(aux)\n",
        "aux = (aux - 127.5) / 127.5\n",
        "\n",
        "# Continue training the model.\n",
        "wgan.fit(aux, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])\n",
        "\n",
        "gen_to_save = wgan.generator\n",
        "dis_to_save = wgan.discriminator\n",
        "gen_to_save.save(\"savedGEN_wgan2_12\")\n",
        "dis_to_save.save(\"savedDIS_wgan2_12\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28b922fc-a94e-4277-a49e-127be225d04c",
        "id": "f1gi8o-L_ma1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "391/391 [==============================] - 144s 369ms/step - d_loss: -6.0767 - g_loss: -72.5058\n",
            "Epoch 2/4\n",
            "391/391 [==============================] - 145s 370ms/step - d_loss: -6.0376 - g_loss: -72.1827\n",
            "Epoch 3/4\n",
            "391/391 [==============================] - 145s 371ms/step - d_loss: -6.1258 - g_loss: -74.9082\n",
            "Epoch 4/4\n",
            "391/391 [==============================] - 145s 370ms/step - d_loss: -5.9561 - g_loss: -75.6143\n",
            "INFO:tensorflow:Assets written to: savedGEN_wgan2_12/assets\n",
            "INFO:tensorflow:Assets written to: savedDIS_wgan2_12/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r savedDIS_wgan2_7.zip savedDIS_wgan2_7/\n",
        "!zip -r savedGEN_wgan2_7.zip savedGEN_wgan2_7/\n",
        "!zip -r savedDIS_wgan2_8.zip savedDIS_wgan2_8/\n",
        "!zip -r savedGEN_wgan2_8.zip savedGEN_wgan2_8/\n",
        "!zip -r savedDIS_wgan2_9.zip savedDIS_wgan2_9/\n",
        "!zip -r savedGEN_wgan2_9.zip savedGEN_wgan2_9/\n",
        "!zip -r savedDIS_wgan2_10.zip savedDIS_wgan2_10/\n",
        "!zip -r savedGEN_wgan2_10.zip savedGEN_wgan2_10/\n",
        "!zip -r savedDIS_wgan2_11.zip savedDIS_wgan2_11/\n",
        "!zip -r savedGEN_wgan2_11.zip savedGEN_wgan2_11/\n",
        "!zip -r savedDIS_wgan2_12.zip savedDIS_wgan2_12/\n",
        "!zip -r savedGEN_wgan2_12.zip savedGEN_wgan2_12/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec6f9b29-04e4-4f10-f512-ab3dac0518ba",
        "id": "48b0mUge_ma3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: savedDIS_wgan2_7/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_7/saved_model.pb (deflated 88%)\n",
            "  adding: savedDIS_wgan2_7/assets/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_7/variables/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_7/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: savedDIS_wgan2_7/variables/variables.index (deflated 62%)\n",
            "  adding: savedDIS_wgan2_7/keras_metadata.pb (deflated 90%)\n",
            "  adding: savedGEN_wgan2_7/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_7/saved_model.pb (deflated 90%)\n",
            "  adding: savedGEN_wgan2_7/assets/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_7/variables/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_7/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "  adding: savedGEN_wgan2_7/variables/variables.index (deflated 68%)\n",
            "  adding: savedGEN_wgan2_7/keras_metadata.pb (deflated 92%)\n",
            "  adding: savedDIS_wgan2_8/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_8/saved_model.pb (deflated 88%)\n",
            "  adding: savedDIS_wgan2_8/assets/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_8/variables/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_8/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: savedDIS_wgan2_8/variables/variables.index (deflated 62%)\n",
            "  adding: savedDIS_wgan2_8/keras_metadata.pb (deflated 90%)\n",
            "  adding: savedGEN_wgan2_8/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_8/saved_model.pb (deflated 89%)\n",
            "  adding: savedGEN_wgan2_8/assets/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_8/variables/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_8/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "  adding: savedGEN_wgan2_8/variables/variables.index (deflated 68%)\n",
            "  adding: savedGEN_wgan2_8/keras_metadata.pb (deflated 92%)\n",
            "  adding: savedDIS_wgan2_9/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_9/saved_model.pb (deflated 88%)\n",
            "  adding: savedDIS_wgan2_9/assets/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_9/variables/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_9/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: savedDIS_wgan2_9/variables/variables.index (deflated 62%)\n",
            "  adding: savedDIS_wgan2_9/keras_metadata.pb (deflated 90%)\n",
            "  adding: savedGEN_wgan2_9/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_9/saved_model.pb (deflated 89%)\n",
            "  adding: savedGEN_wgan2_9/assets/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_9/variables/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_9/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "  adding: savedGEN_wgan2_9/variables/variables.index (deflated 68%)\n",
            "  adding: savedGEN_wgan2_9/keras_metadata.pb (deflated 92%)\n",
            "  adding: savedDIS_wgan2_10/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_10/saved_model.pb (deflated 88%)\n",
            "  adding: savedDIS_wgan2_10/assets/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_10/variables/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_10/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: savedDIS_wgan2_10/variables/variables.index (deflated 62%)\n",
            "  adding: savedDIS_wgan2_10/keras_metadata.pb (deflated 90%)\n",
            "  adding: savedGEN_wgan2_10/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_10/saved_model.pb (deflated 89%)\n",
            "  adding: savedGEN_wgan2_10/assets/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_10/variables/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_10/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "  adding: savedGEN_wgan2_10/variables/variables.index (deflated 68%)\n",
            "  adding: savedGEN_wgan2_10/keras_metadata.pb (deflated 92%)\n",
            "  adding: savedDIS_wgan2_11/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_11/saved_model.pb (deflated 89%)\n",
            "  adding: savedDIS_wgan2_11/assets/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_11/variables/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_11/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: savedDIS_wgan2_11/variables/variables.index (deflated 62%)\n",
            "  adding: savedDIS_wgan2_11/keras_metadata.pb (deflated 90%)\n",
            "  adding: savedGEN_wgan2_11/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_11/saved_model.pb (deflated 89%)\n",
            "  adding: savedGEN_wgan2_11/assets/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_11/variables/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_11/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "  adding: savedGEN_wgan2_11/variables/variables.index (deflated 68%)\n",
            "  adding: savedGEN_wgan2_11/keras_metadata.pb (deflated 92%)\n",
            "  adding: savedDIS_wgan2_12/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_12/saved_model.pb (deflated 88%)\n",
            "  adding: savedDIS_wgan2_12/assets/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_12/variables/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_12/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: savedDIS_wgan2_12/variables/variables.index (deflated 62%)\n",
            "  adding: savedDIS_wgan2_12/keras_metadata.pb (deflated 90%)\n",
            "  adding: savedGEN_wgan2_12/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_12/saved_model.pb (deflated 89%)\n",
            "  adding: savedGEN_wgan2_12/assets/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_12/variables/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_12/variables/variables.data-00000-of-00001 (deflated 9%)\n",
            "  adding: savedGEN_wgan2_12/variables/variables.index (deflated 68%)\n",
            "  adding: savedGEN_wgan2_12/keras_metadata.pb (deflated 92%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ckXegoc_d9ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Epochs 8-10 - by chunks of 1/6 of data"
      ],
      "metadata": {
        "id": "bCxcEEf9d-Ni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_img_folder = \"/content/data0/lsun/bedroom/\""
      ],
      "metadata": {
        "id": "Rd2EsBEbd-Nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3"
      ],
      "metadata": {
        "id": "EJCYO_tbd-Nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indeksior = 0\n",
        "\n",
        "aux = load_images_from_folder_recursively(path_to_img_folder, from_ind = indeksior, to_ind = indeksior + 50000)\n",
        "aux = np.array(aux)\n",
        "aux = (aux - 127.5) / 127.5\n",
        "\n",
        "# Continue training the model.\n",
        "wgan.fit(aux, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])\n",
        "\n",
        "gen_to_save = wgan.generator\n",
        "dis_to_save = wgan.discriminator\n",
        "gen_to_save.save(\"savedGEN_wgan2_13\")\n",
        "dis_to_save.save(\"savedDIS_wgan2_13\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1be0b19b-a684-4538-b3ad-66c344ac2acb",
        "id": "eEr1RuvGd-No"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "391/391 [==============================] - 156s 377ms/step - d_loss: -6.0555 - g_loss: -71.1574\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 146s 373ms/step - d_loss: -6.0271 - g_loss: -70.8523\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 145s 371ms/step - d_loss: -5.9901 - g_loss: -66.4932\n",
            "INFO:tensorflow:Assets written to: savedGEN_wgan2_13/assets\n",
            "INFO:tensorflow:Assets written to: savedDIS_wgan2_13/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indeksior = 50000\n",
        "\n",
        "aux = load_images_from_folder_recursively(path_to_img_folder, from_ind = indeksior, to_ind = indeksior + 50000)\n",
        "aux = np.array(aux)\n",
        "aux = (aux - 127.5) / 127.5\n",
        "\n",
        "# Continue training the model.\n",
        "wgan.fit(aux, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])\n",
        "\n",
        "gen_to_save = wgan.generator\n",
        "dis_to_save = wgan.discriminator\n",
        "gen_to_save.save(\"savedGEN_wgan2_14\")\n",
        "dis_to_save.save(\"savedDIS_wgan2_14\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26f5c53b-3b62-451d-ff70-52ee2686c3d1",
        "id": "wCnDLWpyd-Nq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "391/391 [==============================] - 161s 373ms/step - d_loss: -6.0270 - g_loss: -67.4681\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 145s 370ms/step - d_loss: -5.9337 - g_loss: -69.9540\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 145s 371ms/step - d_loss: -5.9797 - g_loss: -63.7451\n",
            "INFO:tensorflow:Assets written to: savedGEN_wgan2_14/assets\n",
            "INFO:tensorflow:Assets written to: savedDIS_wgan2_14/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indeksior = 100000\n",
        "\n",
        "aux = load_images_from_folder_recursively(path_to_img_folder, from_ind = indeksior, to_ind = indeksior + 50000)\n",
        "aux = np.array(aux)\n",
        "aux = (aux - 127.5) / 127.5\n",
        "\n",
        "# Continue training the model.\n",
        "wgan.fit(aux, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])\n",
        "\n",
        "gen_to_save = wgan.generator\n",
        "dis_to_save = wgan.discriminator\n",
        "gen_to_save.save(\"savedGEN_wgan2_15\")\n",
        "dis_to_save.save(\"savedDIS_wgan2_15\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cad7e4e-70c2-445d-fa76-79d9ad1ca913",
        "id": "Ucd8N5BId-Nr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "391/391 [==============================] - 146s 372ms/step - d_loss: -6.1171 - g_loss: -58.7918\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 145s 370ms/step - d_loss: -5.9945 - g_loss: -55.7685\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 145s 371ms/step - d_loss: -5.9933 - g_loss: -58.3185\n",
            "INFO:tensorflow:Assets written to: savedGEN_wgan2_15/assets\n",
            "INFO:tensorflow:Assets written to: savedDIS_wgan2_15/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indeksior = 150000\n",
        "\n",
        "aux = load_images_from_folder_recursively(path_to_img_folder, from_ind = indeksior, to_ind = indeksior + 50000)\n",
        "aux = np.array(aux)\n",
        "aux = (aux - 127.5) / 127.5\n",
        "\n",
        "# Continue training the model.\n",
        "wgan.fit(aux, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])\n",
        "\n",
        "gen_to_save = wgan.generator\n",
        "dis_to_save = wgan.discriminator\n",
        "gen_to_save.save(\"savedGEN_wgan2_16\")\n",
        "dis_to_save.save(\"savedDIS_wgan2_16\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0f35b58-921d-4632-bb23-bddf3441a0e2",
        "id": "rjdRp9Cld-Nu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "391/391 [==============================] - 146s 372ms/step - d_loss: -6.0156 - g_loss: -61.6580\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 145s 370ms/step - d_loss: -6.0261 - g_loss: -61.3115\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 145s 370ms/step - d_loss: -5.9813 - g_loss: -59.8820\n",
            "INFO:tensorflow:Assets written to: savedGEN_wgan2_16/assets\n",
            "INFO:tensorflow:Assets written to: savedDIS_wgan2_16/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indeksior = 200000\n",
        "\n",
        "aux = load_images_from_folder_recursively(path_to_img_folder, from_ind = indeksior, to_ind = indeksior + 50000)\n",
        "aux = np.array(aux)\n",
        "aux = (aux - 127.5) / 127.5\n",
        "\n",
        "# Continue training the model.\n",
        "wgan.fit(aux, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])\n",
        "\n",
        "gen_to_save = wgan.generator\n",
        "dis_to_save = wgan.discriminator\n",
        "gen_to_save.save(\"savedGEN_wgan2_17\")\n",
        "dis_to_save.save(\"savedDIS_wgan2_17\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bbda640-2124-487f-ebe0-b17f1a763be7",
        "id": "zOChInfbd-Nx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "391/391 [==============================] - 147s 375ms/step - d_loss: -5.9700 - g_loss: -56.5554\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 145s 370ms/step - d_loss: -6.0105 - g_loss: -58.1693\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 145s 371ms/step - d_loss: -5.8860 - g_loss: -59.1123\n",
            "INFO:tensorflow:Assets written to: savedGEN_wgan2_17/assets\n",
            "INFO:tensorflow:Assets written to: savedDIS_wgan2_17/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indeksior = 250000\n",
        "\n",
        "aux = load_images_from_folder_recursively(path_to_img_folder, from_ind = indeksior, to_ind = indeksior + 50000)\n",
        "aux = np.array(aux)\n",
        "aux = (aux - 127.5) / 127.5\n",
        "\n",
        "# Continue training the model.\n",
        "wgan.fit(aux, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])\n",
        "\n",
        "gen_to_save = wgan.generator\n",
        "dis_to_save = wgan.discriminator\n",
        "gen_to_save.save(\"savedGEN_wgan2_18\")\n",
        "dis_to_save.save(\"savedDIS_wgan2_18\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b013cd1f-6a7f-4c5f-fcec-066d0b3739ca",
        "id": "JUhQYqicd-Ny"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "391/391 [==============================] - 146s 372ms/step - d_loss: -5.9230 - g_loss: -46.8884\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 145s 371ms/step - d_loss: -5.8791 - g_loss: -53.6392\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 145s 371ms/step - d_loss: -5.9446 - g_loss: -55.2900\n",
            "INFO:tensorflow:Assets written to: savedGEN_wgan2_18/assets\n",
            "INFO:tensorflow:Assets written to: savedDIS_wgan2_18/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r savedDIS_wgan2_13.zip savedDIS_wgan2_13/\n",
        "!zip -r savedGEN_wgan2_13.zip savedGEN_wgan2_13/\n",
        "!zip -r savedDIS_wgan2_14.zip savedDIS_wgan2_14/\n",
        "!zip -r savedGEN_wgan2_14.zip savedGEN_wgan2_14/\n",
        "!zip -r savedDIS_wgan2_15.zip savedDIS_wgan2_15/\n",
        "!zip -r savedGEN_wgan2_15.zip savedGEN_wgan2_15\n",
        "!zip -r savedDIS_wgan2_16.zip savedDIS_wgan2_16/\n",
        "!zip -r savedGEN_wgan2_16.zip savedGEN_wgan2_16/\n",
        "!zip -r savedDIS_wgan2_17.zip savedDIS_wgan2_17/\n",
        "!zip -r savedGEN_wgan2_17.zip savedGEN_wgan2_17/\n",
        "!zip -r savedDIS_wgan2_18.zip savedDIS_wgan2_18/\n",
        "!zip -r savedGEN_wgan2_18.zip savedGEN_wgan2_18/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c90715-be2d-4412-e15b-4a3a48bfe5ad",
        "id": "dMwXe4sEd-Nz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: savedDIS_wgan2_13/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_13/saved_model.pb (deflated 89%)\n",
            "  adding: savedDIS_wgan2_13/assets/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_13/variables/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_13/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: savedDIS_wgan2_13/variables/variables.index (deflated 48%)\n",
            "  adding: savedDIS_wgan2_13/keras_metadata.pb (deflated 90%)\n",
            "  adding: savedGEN_wgan2_13/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_13/saved_model.pb (deflated 89%)\n",
            "  adding: savedGEN_wgan2_13/assets/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_13/variables/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_13/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: savedGEN_wgan2_13/variables/variables.index (deflated 61%)\n",
            "  adding: savedGEN_wgan2_13/keras_metadata.pb (deflated 92%)\n",
            "  adding: savedDIS_wgan2_14/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_14/saved_model.pb (deflated 89%)\n",
            "  adding: savedDIS_wgan2_14/assets/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_14/variables/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_14/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: savedDIS_wgan2_14/variables/variables.index (deflated 48%)\n",
            "  adding: savedDIS_wgan2_14/keras_metadata.pb (deflated 90%)\n",
            "  adding: savedGEN_wgan2_14/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_14/saved_model.pb (deflated 89%)\n",
            "  adding: savedGEN_wgan2_14/assets/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_14/variables/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_14/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: savedGEN_wgan2_14/variables/variables.index (deflated 61%)\n",
            "  adding: savedGEN_wgan2_14/keras_metadata.pb (deflated 92%)\n",
            "  adding: savedDIS_wgan2_15/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_15/saved_model.pb (deflated 89%)\n",
            "  adding: savedDIS_wgan2_15/assets/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_15/variables/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_15/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: savedDIS_wgan2_15/variables/variables.index (deflated 48%)\n",
            "  adding: savedDIS_wgan2_15/keras_metadata.pb (deflated 90%)\n",
            "  adding: savedGEN_wgan2_15/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_15/saved_model.pb (deflated 89%)\n",
            "  adding: savedGEN_wgan2_15/assets/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_15/variables/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_15/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: savedGEN_wgan2_15/variables/variables.index (deflated 61%)\n",
            "  adding: savedGEN_wgan2_15/keras_metadata.pb (deflated 92%)\n",
            "  adding: savedDIS_wgan2_16/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_16/saved_model.pb (deflated 89%)\n",
            "  adding: savedDIS_wgan2_16/assets/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_16/variables/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_16/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: savedDIS_wgan2_16/variables/variables.index (deflated 48%)\n",
            "  adding: savedDIS_wgan2_16/keras_metadata.pb (deflated 90%)\n",
            "  adding: savedGEN_wgan2_16/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_16/saved_model.pb (deflated 89%)\n",
            "  adding: savedGEN_wgan2_16/assets/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_16/variables/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_16/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: savedGEN_wgan2_16/variables/variables.index (deflated 61%)\n",
            "  adding: savedGEN_wgan2_16/keras_metadata.pb (deflated 92%)\n",
            "  adding: savedDIS_wgan2_17/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_17/saved_model.pb (deflated 89%)\n",
            "  adding: savedDIS_wgan2_17/assets/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_17/variables/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_17/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: savedDIS_wgan2_17/variables/variables.index (deflated 48%)\n",
            "  adding: savedDIS_wgan2_17/keras_metadata.pb (deflated 90%)\n",
            "  adding: savedGEN_wgan2_17/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_17/saved_model.pb (deflated 90%)\n",
            "  adding: savedGEN_wgan2_17/assets/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_17/variables/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_17/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: savedGEN_wgan2_17/variables/variables.index (deflated 61%)\n",
            "  adding: savedGEN_wgan2_17/keras_metadata.pb (deflated 92%)\n",
            "  adding: savedDIS_wgan2_18/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_18/saved_model.pb (deflated 89%)\n",
            "  adding: savedDIS_wgan2_18/assets/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_18/variables/ (stored 0%)\n",
            "  adding: savedDIS_wgan2_18/variables/variables.data-00000-of-00001 (deflated 7%)\n",
            "  adding: savedDIS_wgan2_18/variables/variables.index (deflated 48%)\n",
            "  adding: savedDIS_wgan2_18/keras_metadata.pb (deflated 90%)\n",
            "  adding: savedGEN_wgan2_18/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_18/saved_model.pb (deflated 89%)\n",
            "  adding: savedGEN_wgan2_18/assets/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_18/variables/ (stored 0%)\n",
            "  adding: savedGEN_wgan2_18/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: savedGEN_wgan2_18/variables/variables.index (deflated 61%)\n",
            "  adding: savedGEN_wgan2_18/keras_metadata.pb (deflated 92%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FID calculations"
      ],
      "metadata": {
        "id": "6QH-UOL1OPIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from numpy import cov\n",
        "from numpy import trace\n",
        "from numpy import iscomplexobj\n",
        "from numpy import asarray\n",
        "from numpy.random import randint\n",
        "from scipy.linalg import sqrtm\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.datasets.mnist import load_data\n",
        "from skimage.transform import resize\n",
        " \n",
        "# scale an array of images to a new size\n",
        "def scale_images(images, new_shape):\n",
        "\timages_list = list()\n",
        "\tfor image in images:\n",
        "\t\t# resize with nearest neighbor interpolation\n",
        "\t\tnew_image = resize(image, new_shape, 0)\n",
        "\t\t# store\n",
        "\t\timages_list.append(new_image)\n",
        "\treturn asarray(images_list)\n",
        " \n",
        "# calculate frechet inception distance\n",
        "def calculate_fid(model, images1, images2):\n",
        "\t# calculate activations\n",
        "\tact1 = model.predict(images1)\n",
        "\tact2 = model.predict(images2)\n",
        "\t# calculate mean and covariance statistics\n",
        "\tmu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)\n",
        "\tmu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)\n",
        "\t# calculate sum squared difference between means\n",
        "\tssdiff = numpy.sum((mu1 - mu2)**2.0)\n",
        "\t# calculate sqrt of product between cov\n",
        "\tcovmean = sqrtm(sigma1.dot(sigma2))\n",
        "\t# check and correct imaginary numbers from sqrt\n",
        "\tif iscomplexobj(covmean):\n",
        "\t\tcovmean = covmean.real\n",
        "\t# calculate score\n",
        "\tfid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)\n",
        "\treturn fid\n",
        " \n",
        "# prepare the inception v3 model\n",
        "model = InceptionV3(include_top=False, pooling='avg', input_shape=(75,75,3))"
      ],
      "metadata": {
        "id": "fsi-KFDDtEen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_images = generator(random_latent_vectors, training=True)"
      ],
      "metadata": {
        "id": "bPTYVSMShb30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FID for the WGAN_36"
      ],
      "metadata": {
        "id": "j68VV0t-lR2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FID for the WGAN2_1"
      ],
      "metadata": {
        "id": "iuDMRrj3lbbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(44)\n",
        "\n",
        "random_latent_vectors = tf.random.normal(\n",
        "                shape=(10000, 1024)\n",
        "            )"
      ],
      "metadata": {
        "id": "A2ez1-7wlR6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading saved models\n",
        "\n",
        "gg = keras.models.load_model('savedGEN_wgan2_12')\n",
        "dd = keras.models.load_model('savedDIS_wgan2_12')\n",
        "wgan.discriminator = dd\n",
        "wgan.generator = gg"
      ],
      "metadata": {
        "id": "NJ3rA_LbZN99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training for additional 1 epoch\n",
        "epochs = 1"
      ],
      "metadata": {
        "id": "jif3J2hAlpRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indeksior = 200000\n",
        "\n",
        "real_images = load_images_from_folder_recursively(path_to_img_folder, from_ind = indeksior, to_ind = indeksior + 10000)\n",
        "real_images = np.array(real_images)\n",
        "real_images = (real_images - 127.5) / 127.5\n",
        "\n"
      ],
      "metadata": {
        "id": "n9-b6gKSlpRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_images = scale_images(real_images, (75,75,3))"
      ],
      "metadata": {
        "id": "42SoezMVuUE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generator = wgan.generator\n",
        "fake_images = gg.predict(random_latent_vectors)"
      ],
      "metadata": {
        "id": "TnUG2p97kElv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resize images\n",
        "# real_images = scale_images(real_images, (75,75,3))\n",
        "fake_images = scale_images(fake_images, (75,75,3))\n",
        "print('Scaled', real_images.shape, fake_images.shape)\n",
        "\n",
        "fid = calculate_fid(model, real_images, fake_images)\n",
        "print('FID (different): %.3f' % fid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lc3bvoEkhe_n",
        "outputId": "b9f1a2f7-b6e4-4063-ff15-6ee3c64be2fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled (10000, 75, 75, 3) (10000, 75, 75, 3)\n",
            "FID (different): 762.734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "P1iQSmZ0oKQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FID for the WGAN2_2"
      ],
      "metadata": {
        "id": "_tPuCBMkaQPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading saved models\n",
        "\n",
        "gg = keras.models.load_model('savedGEN_wgan2_2')\n",
        "# dd = keras.models.load_model('savedDIS_wgan2_1')\n",
        "# wgan.discriminator = dd\n",
        "# wgan.generator = gg"
      ],
      "metadata": {
        "id": "pagzA2MDaQP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generator = wgan.generator\n",
        "fake_images = gg.predict(random_latent_vectors)"
      ],
      "metadata": {
        "id": "2orAfwJWaQP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resize images\n",
        "# real_images = scale_images(real_images, (75,75,3))\n",
        "fake_images = scale_images(fake_images, (75,75,3))\n",
        "print('Scaled', real_images.shape, fake_images.shape)\n",
        "\n",
        "fid = calculate_fid(model, real_images, fake_images)\n",
        "print('FID (different): %.3f' % fid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f36c8ec1-9819-4593-ddd8-7bdd8692c1c8",
        "id": "h3M53hDsaQP7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled (10000, 75, 75, 3) (10000, 75, 75, 3)\n",
            "FID (different): 791.204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4AZ3kFzYaPzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FID for the WGAN2_(3-18)"
      ],
      "metadata": {
        "id": "WtaQ4tTvaaxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading saved models\n",
        "for i in range(3,10):\n",
        "  gg = keras.models.load_model('savedGEN_wgan2_' + str(i))\n",
        "  fake_images = gg.predict(random_latent_vectors)\n",
        "  fake_images = scale_images(fake_images, (75,75,3))\n",
        "  fid = calculate_fid(model, real_images, fake_images)\n",
        "  print( str(i)+ ': FID : %.3f' % fid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjfGNpp4aaxw",
        "outputId": "07c57c9e-1114-43e7-e5b2-8043f894341f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3: FID : 616.650\n",
            "4: FID : 574.166\n",
            "5: FID : 563.132\n",
            "6: FID : 508.083\n",
            "7: FID : 436.825\n",
            "8: FID : 402.532\n",
            "9: FID : 437.107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading saved models\n",
        "for i in range(11,13):\n",
        "  gg = keras.models.load_model('savedGEN_wgan2_' + str(i))\n",
        "  fake_images = gg.predict(random_latent_vectors)\n",
        "  fake_images = scale_images(fake_images, (75,75,3))\n",
        "  fid = calculate_fid(model, real_images, fake_images)\n",
        "  print( str(i)+ ': FID : %.3f' % fid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fx0RIXSKaaxy",
        "outputId": "47ccbb69-cabb-46ca-f093-88d6f5acd7d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11: FID : 382.734\n",
            "12: FID : 398.523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading saved models\n",
        "for i in range(13,19):\n",
        "  gg = keras.models.load_model('savedGEN_wgan2_' + str(i))\n",
        "  fake_images = gg.predict(random_latent_vectors)\n",
        "  fake_images = scale_images(fake_images, (75,75,3))\n",
        "  fid = calculate_fid(model, real_images, fake_images)\n",
        "  print( str(i)+ ': FID : %.3f' % fid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_Xh5UI0aax1",
        "outputId": "f1a2fce8-4fa7-4076-8e71-d40ff73d320b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13: FID : 366.144\n",
            "14: FID : 417.012\n",
            "15: FID : 379.827\n",
            "16: FID : 366.437\n",
            "17: FID : 358.371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "P6t3ojzIaP2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pqf6GPY5aP46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QXLlG-KGaP7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rCkhq254aP-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FID for the WGAN_34\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D29MFLDbuqqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(44)\n",
        "\n",
        "random_latent_vectors = tf.random.normal(\n",
        "                shape=(10000, 128)\n",
        "            )"
      ],
      "metadata": {
        "id": "uzde1FoDuqqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "pathToDrive = \"drive/MyDrive/gan/\"\n",
        " \n",
        "zip_file = pathToDrive+\"savedGEN_wgan1_34.zip\"\n",
        " \n",
        "try:\n",
        "    with zipfile.ZipFile(zip_file) as z:\n",
        "        z.extractall()\n",
        "        print(\"Extracted all\")\n",
        "except:\n",
        "    print(\"Invalid file\")\n",
        "\n",
        "\n",
        "zip_file = pathToDrive+\"savedDIS_wgan1_34.zip\"\n",
        " \n",
        "try:\n",
        "    with zipfile.ZipFile(zip_file) as z:\n",
        "        z.extractall()\n",
        "        print(\"Extracted all\")\n",
        "except:\n",
        "    print(\"Invalid file\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tN9TTlBRuqqV",
        "outputId": "98510763-12cd-49eb-fa83-f23507ab8b15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted all\n",
            "Extracted all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading saved models\n",
        "\n",
        "gg = keras.models.load_model('savedGEN_wgan1_34')\n",
        "dd = keras.models.load_model('savedDIS_wgan1_34')\n",
        "wgan.discriminator = dd\n",
        "wgan.generator = gg\n"
      ],
      "metadata": {
        "id": "BSHsgukduqqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indeksior = 200000\n",
        "\n",
        "real_images = load_images_from_folder_recursively(path_to_img_folder, from_ind = indeksior, to_ind = indeksior + 10000)\n",
        "real_images = np.array(real_images)\n",
        "real_images = (real_images - 127.5) / 127.5\n",
        "\n",
        "# Continue training the model.\n",
        "wgan.fit(real_images, batch_size=BATCH_SIZE, epochs=epochs, callbacks=[cbk])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0549b77d-a5b4-4c13-81b8-30a4b465dfce",
        "id": "WoJRE6n5uqqa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 115s 1s/step - d_loss: -2.3930 - g_loss: 19.0538\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc0cf42f150>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = wgan.generator\n",
        "fake_images = generator.predict(random_latent_vectors)"
      ],
      "metadata": {
        "id": "z0QY_70Iuqqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resize images\n",
        "real_images = scale_images(real_images, (75,75,3))\n",
        "fake_images = scale_images(fake_images, (75,75,3))\n",
        "print('Scaled', real_images.shape, fake_images.shape)\n",
        "\n",
        "fid = calculate_fid(model, real_images, fake_images)\n",
        "print('FID: %.3f' % fid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08ee7f90-d222-4cbe-8ab9-b877f22cd9c0",
        "id": "jRrQtSlSuqqd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled (10000, 75, 75, 3) (10000, 75, 75, 3)\n",
            "FID: 213.603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = wgan.generator\n",
        "fake_images = generator.predict(random_latent_vectors)"
      ],
      "metadata": {
        "id": "M5pEBBfrhhVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resize images\n",
        "real_images = scale_images(real_images, (75,75,3))\n",
        "fake_images = scale_images(fake_images, (75,75,3))\n",
        "print('Scaled', real_images.shape, fake_images.shape)\n",
        "\n",
        "fid = calculate_fid(model, real_images, fake_images)\n",
        "print('FID: %.3f' % fid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfce44e2-3066-4d92-91f6-74a2bd87412e",
        "id": "aprvKIqshhVw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled (10000, 75, 75, 3) (10000, 75, 75, 3)\n",
            "FID: 180.121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "O6RuPJTcKXqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# quick plot\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "y = [339,251,246,227,209,228,197,213,196, 174, 176, 177, 171, 176, 180]\n",
        "x = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
        "\n",
        "ax = sns.lineplot(x = x, y = y)\n",
        "\n",
        "ax.set_ylabel('FID')\n",
        "\n",
        "ax.set_xlabel('Time interval, 1 = about 2 epochs')\n",
        "\n",
        "ax.set_title(\"WGAN-GP training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "rtSDhQhSy5z8",
        "outputId": "c2552e90-ce4e-4115-b6fb-76094ab661bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'WGAN-GP training')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# quick plot\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "y = [762,791,616,574,563,508,436,402,437,382,398, 366, 417, 379, 366, 358]\n",
        "x = [1,2,3,4,5,6,7,8,9,11,12, 13, 14, 15, 16, 17]\n",
        "\n",
        "ax = sns.lineplot(x = x, y = y)\n",
        "\n",
        "ax.set_ylabel('FID')\n",
        "\n",
        "ax.set_xlabel('Time interval, 1 = about 1/2 of epoch')\n",
        "\n",
        "ax.set_title(\"WGAN2-GP training\")"
      ],
      "metadata": {
        "id": "0wSlXrs80C04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "ca71b199-0ee3-4c30-a605-b443529fc1d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'WGAN2-GP training')"
            ]
          },
          "metadata": {},
          "execution_count": 1
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}